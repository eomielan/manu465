{"cells":[{"cell_type":"markdown","metadata":{"id":"I4DAlrQRqSVd"},"source":["# California House Price Model"]},{"cell_type":"markdown","metadata":{"id":"-7oVdVWzqSVf"},"source":["## Project Description\n","Your task is to predict the average house values in Californian districts, given a number of features for each district:\n","- Location (Longitude and Latitude)\n","- Average Houses' Age\n","- Total Rooms\n","- Total Bedrooms\n","- District Population\n","- Number of Households\n","- Average Annual Income\n","- Average House Value\n","- Proximity to Ocean Categories:One Hour Away from Ocean (1H Ocean), Inland, Near Ocean, Near Bay, Island    "]},{"cell_type":"markdown","metadata":{"id":"4mLbSmQCqSVh"},"source":["## 1. Import the Basic Libraries"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"uC3FbBjI4YIU"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KlxBB9BJqSVh"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"cjbuCcZ_qSVi"},"source":["## 2. Importing the Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CTwriS_7qSVk"},"outputs":[],"source":["#data = pd.read_csv('CaliforniaHouseData.csv')\n","data = pd.read_csv()\n","data.head()"]},{"cell_type":"markdown","source":["### 2.1 Display a Random Sample of Data"],"metadata":{"id":"gNHCu06orCDU"}},{"cell_type":"code","source":["import random\n","my_random_subset = random.sample(range(len(data)), 10)\n","data.iloc[my_random_subset]"],"metadata":{"id":"MEOESy56rIM7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lkge0G5OqSVk"},"source":["## 3. Exploratory Data Analysis (EDA)\n","In this step, we will use data visualization methods to explore the main characteristics of the dataset."]},{"cell_type":"markdown","metadata":{"id":"IMGehDL-qSVk"},"source":["### 3.1. Reviewing the data for some general information"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EZqhxiUlqSVl"},"outputs":[],"source":["data.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vmGq2gFRqSVl"},"outputs":[],"source":["data['Ocean_proximity'].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"WrxLNIypqSVm"},"source":["### 3.2. Reviewing overall statistical information"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"zCm58mGXqSVm"},"outputs":[],"source":["data.describe()"]},{"cell_type":"markdown","metadata":{"id":"zXwGPhajqSVn"},"source":["### 3.3. Getting some insights by plotting differnet variables"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZCw9zeH_qSVn"},"outputs":[],"source":["data.hist()"]},{"cell_type":"markdown","metadata":{"id":"6xHV-pfmqSVn"},"source":["### 3.4. Visualizing the data based on the location"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vQRMZqlBqSVo"},"outputs":[],"source":["data.plot(kind = 'scatter', )"]},{"cell_type":"markdown","metadata":{"id":"7CMNO8QgqSVo"},"source":["If you pay attention, you notice, the shape of the above graph looks like California! We can also add a new paramter, alpha (transparency), to show shows the denser area with a more intense color. Let's set alpha= 0.05, 0.1, 0.3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xWxMTaJAqSVo"},"outputs":[],"source":["for :\n","  data.plot(kind = 'scatter', x = 'Longitude', y = 'Latitude', alpha = )\n","  \n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"bHAFrFk0qSVp"},"source":["Now, you can clearly see some high-density areas: e.g., areas near the Bay area, Los Angeles, and San Diego. Furthermore, we can visualize the data to check if housing price is related to location and population density."]},{"cell_type":"markdown","metadata":{"id":"8XgQjM2HqSVp"},"source":["### 3.5. Visualizing the data based on the house value and population\n","We can plot the above graph; but this time we show each district's population by radius of each circle (option s), and the color represnts the price (option c). So, the bigger the radius of the dots, means higher population, and a range of colors for the value.   "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wunm9WADqSVp"},"outputs":[],"source":["data.plot(kind = 'scatter', x = 'Longitude', y = 'Latitude', label = 'Population',\n","          s = , c = , cmap = plt.get_cmap('jet'),\n","          colorbar = True, alpha = 0.1, figsize = [15, 10])\n","plt.legend()"]},{"cell_type":"markdown","metadata":{"id":"9_OBK2BBqSVp"},"source":["We can see that housing price seems to be very related to location and population density."]},{"cell_type":"markdown","metadata":{"id":"-bP0l436qSVp"},"source":["### 3.6. Checking correlations with the house value\n","- Here, we want to see how house value correlates to differnt parameters. We can compute the standard correlation coefficint (The Pearsons's r) between house value and other parameters. \n","- The correlation coefficient ranges from -1 to +1. When it is close to +1, it means that there is a strong positive correlation (for example, by increasing the parameter the house value goes up); and when it is close to -1, it means that there is a strong negative correlation(for example, by increasing the parameter the house value comes down).<br>\n","- Please note, correlation coefficient 1 means, comparing a parameter with itself. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Qz-pq_lqSVq"},"outputs":[],"source":["r_matrix = data.corr()\n","r_matrix.head()"]},{"cell_type":"markdown","source":["**Create a Heatmap for the correlation Matrix**"],"metadata":{"id":"3r-dBMNzug2e"}},{"cell_type":"code","source":["r_mask = np.triu(np.ones_like(r_matrix, dtype = bool))\n","from seaborn import heatmap\n","plt.figure(figsize = [6,5], dpi = 100)\n","plt.title('Correlatin Heatmap')\n","heatmap(, mask=, annot=True, lw=1, linecolor='White', cmap='Blues', fmt = \"0.2f\")"],"metadata":{"id":"z3-RmdGOuOS-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["r_matrix['Value'].sort_values()"],"metadata":{"id":"VBsgINesvRR7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.plot(kind = 'scatter', x = '', y = '', alpha = 0.2, figsize = [7, 5]) #plot the most correlated ones"],"metadata":{"id":"XSSx1Phzvlyb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.plot(kind = 'scatter', x = '', y = '', alpha = 0.2, figsize = [7, 5]) #plot the most inversely correlaed ones"],"metadata":{"id":"ZsTzKvN1vzEO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tULks3CcqSVq"},"source":["### 3.7. Creating new features and checking their correlations with the house value"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tCWjUa2aqSVq"},"outputs":[],"source":["data[\"Rooms_per_household\"] = data[\"Total_rooms\"] / data[\"Households\"]\n","data[\"Bedrooms_per_room\"] = data[\"\"] / data[\"\"]\n","data[\"Population_per_household\"] = data[\"\"] / data[\"\"]\n","r_matrix = data.corr()\n","r_matrix"]},{"cell_type":"code","source":["r_mask = np.triu(np.ones_like(r_matrix, dtype = bool))\n","from seaborn import heatmap\n","plt.figure(figsize = [7,6], dpi = 100)\n","plt.title('Correlatin Heatmap')\n","heatmap(r_matrix, mask=r_mask, annot=True, lw=1, linecolor='White', cmap='magma', fmt = \"0.2f\")"],"metadata":{"id":"nP3MAH5FwKE8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["r_matrix['Value'].sort_values()"],"metadata":{"id":"W8NUTfNswYkt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UFDaj5oXqSVr"},"source":["Rooms_per_household and bedrooms_per_room have better correlations with the house value than population_per_household."]},{"cell_type":"markdown","metadata":{"id":"92UoxjqnqSVr"},"source":["## 4. Preprocessing the Data for Machine Learning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yQrFENihqSVr"},"outputs":[],"source":["data.info()"]},{"cell_type":"markdown","metadata":{"id":"xTX3uSiQqSVr"},"source":["### 4.1. Rearranging the sequence of the data\n","- Put all numerical data in the first 10 columns.\n","- Put house value at the 2nd last column.\n","- Put the catogorical data (ocean proximity) as the last column."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CsBnsEs5qSVr"},"outputs":[],"source":["my_string = data.columns\n","my_string"]},{"cell_type":"code","source":["new_columns = []\n","data = data.reindex(columns=new_columns)"],"metadata":{"id":"88s1s0ebwn3p"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tdB5_aIXqSVr"},"outputs":[],"source":["data.info()"]},{"cell_type":"markdown","metadata":{"id":"1DVsUahBqSVs"},"source":["We have some missing data."]},{"cell_type":"markdown","metadata":{"id":"ueWpPYqCqSVs"},"source":["### 4.2. Seperating the input data from the output data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K_2I9KqAqSVt"},"outputs":[],"source":["X = data.iloc[].values #skipping Ocean_proximity for now\n","y = data.iloc[].values"]},{"cell_type":"markdown","metadata":{"id":"_hDyCXxiqSVt"},"source":["### 4.3. Imputing the missing numerical data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TFY9rj1EqSVu"},"outputs":[],"source":["from sklearn.impute import SimpleImputer\n","my_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n","X = my_imputer.fit_transform(X)"]},{"cell_type":"markdown","metadata":{"id":"GDxgD1UcqSVu"},"source":["### 4.4. Taking care of the outliers in the numerical data"]},{"cell_type":"code","source":["from sklearn.neighbors import LocalOutlierFactor\n","my_lof = LocalOutlierFactor(contamination=0.01)\n","y_hat = my_lof.fit_predict(X) #returns +1 for inliers and -1 for outliers\n","outlier_mask = (y_hat != )\n","print('Before Outlier removal:\\nX.shape = ', X.shape, ' and y.shape = ', y.shape)\n","X, y = X[], y[]\n","print('After Outlier removal: \\nX.shape = ', X.shape, ' and y.shape = ', y.shape)"],"metadata":{"id":"2f_6o5jTxPzN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"443zWElxqSVs"},"source":["### 4.5. Scaling the numerical data "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OhCmV5olqSVu"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","my_sc = StandardScaler()\n","X_std = my_sc.fit_transform(X)"]},{"cell_type":"markdown","metadata":{"id":"s1NiM3BgqSVu"},"source":["### 4.6. Encoding the categorical data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PNUsKEH2qSVu"},"outputs":[],"source":["from sklearn.preprocessing import OneHotEncoder\n","my_enc = OneHotEncoder()\n","encoded_data = my_enc.fit_transform(data['Ocean_proximity'].values.reshape(-1, 1)).toarray()\n","# my_enc.fit_transform() accepts only column vectors and returns sparse matrix\n","# you need to convert the matrix into ndarray\n","encoded_data.shape"]},{"cell_type":"code","source":["encoded_data = encoded_data[outlier_mask]\n","encoded_data.shape"],"metadata":{"id":"5bpZ5pZ8z5AJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a6m4ft-sqSVu"},"source":["##### Combining the numerical and categorical training data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pSggsFDDqSVv"},"outputs":[],"source":["X = np.concatenate((X, encoded_data), axis = )"]},{"cell_type":"markdown","metadata":{"id":"VEcWmZw7qSVv"},"source":["##### A quick check on the preprocssed training data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bNv_eckEqSVv"},"outputs":[],"source":["pd.DataFrame(X)"]},{"cell_type":"markdown","metadata":{"id":"ZPvleHJ3qSVw"},"source":["### 4.7. Splitting the dataset into the training set and test Set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jsjEuJH-qSVw"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"]},{"cell_type":"markdown","metadata":{"id":"iD2hgUq-qSVw"},"source":["## 5. Training the Linear Regression Model with the Training Set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xgYUEM5rqSVw"},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","my_model = LinearRegression()\n","my_model.fit(, )"]},{"cell_type":"markdown","metadata":{"id":"K7PxdJe8qSVw"},"source":["## 6. Checking the Trained Model with the Test Set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FG0nRxCKqSVx"},"outputs":[],"source":["y_pred = my_model.predict()\n","from sklearn.metrics import r2_score\n","score = r2_score(y_test, y_pred)\n","print('R2 Score = %.3f' %score)"]},{"cell_type":"markdown","source":["# 7. Exploring other methods\n"],"metadata":{"id":"BJIB6sUI0PEx"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor\n","rf=RandomForestRegressor(n_estimators=30)\n","rf.fit(X_train,y_train)\n","y_pred = rf.predict(X_test)\n","rf_score = r2_score(y_test,y_pred)\n","print('R2 Score = %.3f' %rf_score)"],"metadata":{"id":"65ZcweIr0QIR"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"nav_menu":{"height":"279px","width":"309px"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":"block","toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"provenance":[{"file_id":"1HbzkzYEsYtXY-YIHEui6LA2emFXGJ1ju","timestamp":1664162697166}]}},"nbformat":4,"nbformat_minor":0}